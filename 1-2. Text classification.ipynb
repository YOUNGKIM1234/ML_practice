{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOUNGKIM1234/ML_practice/blob/master/1-2.%20Text%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4PU6M6KadaUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 영화 리뷰 분류하기\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZcuQdBL7do49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a971ec50-0bd7-43d3-bd29-becc98ea258a"
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "# num_words = 10000 : 빈도수 가장 높은 만 개의 단어를 가져옴."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gnWIeotRdr8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2a771f1-1fbd-43fd-c1e2-45be0ec29954"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))\n",
        "# 2만5천개의 data가 있음."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8rProIjqd4xg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1908c811-036f-4555-f50f-722257087155"
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])\n",
        "# 각 데이터는 길이가 고르지 못하므로 모두 동일하게 맞춰줘야함."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "kSmUqx5dd7w_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DLxkcMG1eKXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fed6c4f9-42f2-44d1-86ea-970f41512eeb"
      },
      "cell_type": "code",
      "source": [
        "word_index['i']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Be1bvt72fAPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# word_index = word->index\n",
        "# index의 맨 앞에 4개 옵션을 추가하느라 받아온 인덱스의 순서를 +3씩 조정해줌.\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2 #Unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# reverse_word_index = index->word\n",
        "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
        "\n",
        "def decode_review(text) :\n",
        "  return ' '.join([reverse_word_index.get(i,'?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGKXEHqIfKr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "23460840-9449-4ca5-ca75-90653427fb56"
      },
      "cell_type": "code",
      "source": [
        "decode_review(train_data[0])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "EH0gi-uPfL6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 앞쪽에 0을 넣는 post패딩. value = word_index[\"<PAD>\"] : 0이므로 지정안하고 0 넣어도 됨.\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3aGvn5FjXMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bd65eec-fcfb-45f1-ef90-949f36f3c59e"
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "E6Ou-TJmjXdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "bc239b2e-e4d1-4e6f-f8e2-8524d4dd288b"
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# model.summary() 를 이용하면 밑과 같이 쭉 보여줌. 짱편하네 외우자"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9c5-iJBXjZzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lEGVeXEHjidI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSnarvEHjkiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1462
        },
        "outputId": "1460e2c4-08a7-4c68-a978-a98cf249174f"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 67us/step - loss: 0.6914 - acc: 0.6285 - val_loss: 0.6888 - val_acc: 0.7345\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.6843 - acc: 0.7479 - val_loss: 0.6794 - val_acc: 0.7014\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.6704 - acc: 0.7536 - val_loss: 0.6624 - val_acc: 0.7484\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.6473 - acc: 0.7606 - val_loss: 0.6373 - val_acc: 0.7772\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.6146 - acc: 0.7972 - val_loss: 0.6028 - val_acc: 0.7876\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.5740 - acc: 0.8148 - val_loss: 0.5636 - val_acc: 0.7990\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.5288 - acc: 0.8336 - val_loss: 0.5221 - val_acc: 0.8192\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.4830 - acc: 0.8486 - val_loss: 0.4816 - val_acc: 0.8342\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.4401 - acc: 0.8598 - val_loss: 0.4453 - val_acc: 0.8455\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.4013 - acc: 0.8737 - val_loss: 0.4145 - val_acc: 0.8522\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.3686 - acc: 0.8822 - val_loss: 0.3912 - val_acc: 0.8556\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.3413 - acc: 0.8885 - val_loss: 0.3686 - val_acc: 0.8647\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 1s 59us/step - loss: 0.3166 - acc: 0.8957 - val_loss: 0.3527 - val_acc: 0.8683\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2963 - acc: 0.9008 - val_loss: 0.3386 - val_acc: 0.8723\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2787 - acc: 0.9047 - val_loss: 0.3277 - val_acc: 0.8743\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2636 - acc: 0.9089 - val_loss: 0.3187 - val_acc: 0.8769\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2491 - acc: 0.9157 - val_loss: 0.3112 - val_acc: 0.8783\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2366 - acc: 0.9199 - val_loss: 0.3050 - val_acc: 0.8809\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2249 - acc: 0.9237 - val_loss: 0.3001 - val_acc: 0.8814\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.2147 - acc: 0.9265 - val_loss: 0.2959 - val_acc: 0.8820\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.2048 - acc: 0.9301 - val_loss: 0.2924 - val_acc: 0.8829\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1957 - acc: 0.9341 - val_loss: 0.2902 - val_acc: 0.8830\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 1s 59us/step - loss: 0.1874 - acc: 0.9371 - val_loss: 0.2883 - val_acc: 0.8844\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 1s 59us/step - loss: 0.1791 - acc: 0.9423 - val_loss: 0.2861 - val_acc: 0.8837\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1718 - acc: 0.9455 - val_loss: 0.2851 - val_acc: 0.8844\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1645 - acc: 0.9480 - val_loss: 0.2846 - val_acc: 0.8847\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1585 - acc: 0.9512 - val_loss: 0.2849 - val_acc: 0.8848\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 1s 59us/step - loss: 0.1521 - acc: 0.9533 - val_loss: 0.2842 - val_acc: 0.8864\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1462 - acc: 0.9545 - val_loss: 0.2846 - val_acc: 0.8857\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1411 - acc: 0.9574 - val_loss: 0.2857 - val_acc: 0.8861\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1351 - acc: 0.9603 - val_loss: 0.2867 - val_acc: 0.8860\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1303 - acc: 0.9619 - val_loss: 0.2882 - val_acc: 0.8854\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1250 - acc: 0.9649 - val_loss: 0.2898 - val_acc: 0.8857\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1205 - acc: 0.9665 - val_loss: 0.2922 - val_acc: 0.8848\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1165 - acc: 0.9669 - val_loss: 0.2934 - val_acc: 0.8846\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1116 - acc: 0.9697 - val_loss: 0.2961 - val_acc: 0.8841\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1078 - acc: 0.9705 - val_loss: 0.2987 - val_acc: 0.8844\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.1044 - acc: 0.9710 - val_loss: 0.3012 - val_acc: 0.8841\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 1s 57us/step - loss: 0.1001 - acc: 0.9727 - val_loss: 0.3033 - val_acc: 0.8839\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 1s 58us/step - loss: 0.0964 - acc: 0.9751 - val_loss: 0.3064 - val_acc: 0.8836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zomXWtDvjkzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7efea713-0f24-4d76-edab-e67bb975f4f1"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 36us/step\n",
            "[0.3263741688776016, 0.87268]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_UXwgBwWjoN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08534e13-0cf0-41ff-a5e8-e6dea2e375cc"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "9kLKfpPkjoeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}